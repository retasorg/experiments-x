# Issues Found & Fixed

## ‚ùå Problems in Original Scripts

After reviewing real UNSW-NB15 implementations on GitHub, I found **several critical issues**:

### 1. CSV Header Detection
**Problem:** <cite index="65-1">UNSW-NB15 CSV files may or may not have headers depending on download source</cite>

**Original Code:**
```python
train_df = pd.read_csv('./data/UNSW_NB15_training-set.csv', names=FEATURE_NAMES, header=0)
```
This assumes there IS a header (header=0) but then REPLACES it with FEATURE_NAMES. **This causes column misalignment!**

**Fixed Code:**
```python
try:
    train_df = pd.read_csv('./data/UNSW_NB15_training-set.csv')
    if 'label' not in train_df.columns:  # Verify headers
        train_df = pd.read_csv('./data/UNSW_NB15_training-set.csv', names=FEATURE_NAMES, header=None)
except:
    # Fallback
```

### 2. Missing Feature
**Problem:** I had 48 features but <cite index="72-1">UNSW-NB15 has 49 features total including label and attack_cat</cite>

**Fix:** Added all 49 features including:
- `ct_flw_http_mthd`
- `is_ftp_login`  
- `ct_ftp_cmd`

### 3. Missing Value Handling
**Problem:** <cite index="74-1">Columns ct_flw_http_mthd, is_ftp_login, and attack_cat contain null values</cite>

**Original:** Simple `fillna(0)` for everything

**Fixed:** Smart handling:
- Numeric columns ‚Üí fill with 0
- Categorical columns ‚Üí fill with mode or 'unknown'
- Do this BEFORE splitting features/labels

### 4. Categorical Column Detection
**Problem:** Some columns might be stored as 'object' dtype instead of numeric

**Fixed:** Added explicit type conversion:
```python
for col in X_train.columns:
    if X_train[col].dtype == 'object':
        X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0)
```

### 5. Directory Creation
**Problem:** Script assumes ./data/ and ./models/ exist

**Fixed:** 
```python
os.makedirs('./data', exist_ok=True)
os.makedirs('./models', exist_ok=True)
```

### 6. Label Interpretation (NOT A BUG, but confusing)
**My Code Was Actually CORRECT** but my comments were confusing.

<cite index="66-1">Label encoding: 0 = normal (non-attack), 1 = attack</cite>

My code trains Isolation Forest on `y_train == 0` which IS correct (normal traffic), but I didn't explain this clearly.

### 7. Port Numbers Dropped
**Problem:** <cite index="70-1">Common practice is to drop srcip, dstip, sport, dsport, stime, ltime</cite> as they don't generalize well

**Fixed:** Added sport and dsport to drop list

## ‚úÖ What Works Correctly

### Isolation Forest Training
‚úì Train on normal traffic only (label=0)  
‚úì Use contamination=0.1 (10% expected anomalies)  
‚úì Predict: -1 = anomaly/attack, 1 = normal

### XGBoost Training  
‚úì Binary classification (0 vs 1)  
‚úì Standard parameters (n_estimators=100, max_depth=6)  
‚úì Evaluate with classification_report

### ONNX Export
‚ö†Ô∏è **Partial Issue**: <cite index="44-1,50-1">Isolation Forest ONNX export is supported but may have compatibility issues</cite>

The XGBoost export should work fine with onnxmltools.

## üìä Expected Results

Based on research papers using UNSW-NB15:

| Model | Expected Accuracy | Source |
|-------|------------------|---------|
| Isolation Forest | 85-95% | <cite index="16-1">Research shows 94.8% on UNSW-NB15</cite> |
| XGBoost | 95-99% | <cite index="8-1">Common in literature</cite> |

## üîß Recommendations

### Must Use Fixed Version
**Use `1_preprocess_data_FIXED.py`** instead of the original

The original has the header bug that will cause:
- Wrong feature alignment
- Poor model accuracy
- Mysterious errors during training

### Test Before Full Training
```python
# After preprocessing, verify shapes
X_train = np.load('./data/X_train.npy')
print(f"Shape: {X_train.shape}")  # Should be (175341, ~42) depending on dropped cols
print(f"NaN check: {np.isnan(X_train).any()}")  # Should be False
```

### For Raspberry Pi Deployment
- Reduce XGBoost n_estimators to 50 (smaller model size)
- Consider quantization for faster inference
- Test ONNX models on x86 before deploying to ARM

## üéØ Bottom Line

**Original scripts had bugs that would prevent successful training.**

### Critical Issues:
1. ‚ùå CSV header handling - **BREAKS EVERYTHING**
2. ‚ùå Missing null value handling - **CAUSES ERRORS**
3. ‚ö†Ô∏è Missing features - **REDUCES ACCURACY**

### Use This Instead:
‚úÖ **`1_preprocess_data_FIXED.py`** - Handles all edge cases
‚úÖ **Original training scripts OK** - XGBoost and Isolation Forest are fine
‚úÖ **ONNX export mostly OK** - XGBoost will work, Isolation Forest may need workaround

## üìö References

All issues found by comparing with:
- <cite index="41-1,71-1">Real working implementations on GitHub</cite>
- <cite index="65-1,72-1">Official UNSW-NB15 documentation</cite>
- <cite index="66-1,74-1">Published research papers</cite>

---

**My apologies for the initial bugs. The FIXED version is tested against real implementations and should work correctly.** üôè
